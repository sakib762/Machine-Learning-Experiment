{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyPE6sfPmK9J0T+AfxIeJ6Di",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakib762/Machine-Learning-Experiment/blob/main/Twitter_Sentiment_ML_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About Dataset\n",
        "**Context**\n",
        "\n",
        "This is the sentiment140 dataset. It contains 1,600,000 tweets extracted using the twitter api . The tweets have been annotated (0 = negative, 4 = positive) and they can be used to detect sentiment .\n",
        "\n",
        "\n",
        "**Content**\n",
        "\n",
        "It contains the following 6 fields:\n",
        "\n",
        "target: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
        "\n",
        "ids: The id of the tweet ( 2087)\n",
        "\n",
        "date: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
        "\n",
        "flag: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
        "\n",
        "user: the user that tweeted (robotickilldozr)\n",
        "\n",
        "text: the text of the tweet (Lyx is cool)\n",
        "\n",
        "\n",
        "**Acknowledgements**\n",
        "\n",
        "The official link regarding the dataset with resources about how it was generated is here\n",
        "The official paper detailing the approach is here\n",
        "\n",
        "Citation: Go, A., Bhayani, R. and Huang, L., 2009. Twitter sentiment classification using distant supervision. CS224N Project Report, Stanford, 1(2009), p.12."
      ],
      "metadata": {
        "id": "_dEOQbH-CE_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Dependencies"
      ],
      "metadata": {
        "id": "l7V-OH1ADay5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing dependency\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "aKXcL4P2Fx-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "G-x40jSGGY6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "MquXTvfYGs7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection"
      ],
      "metadata": {
        "id": "R3VS4ezWG9bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2sP_J9VADqKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/database/ML Project Database/twitter sentiment.csv', encoding='latin-1')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "xX57wCyDEnrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "JvC8exbcEx6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "7bGQ2xyME8Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "yImjJGB5GCSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df shape\n",
        "df.shape"
      ],
      "metadata": {
        "id": "KpgSdbiTHMyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis"
      ],
      "metadata": {
        "id": "7eB_5zKVGHeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Naming the column\n",
        "column_names = [\"target\",\"id\",\"date\",\"flag\",\"user\",\"text\"]\n",
        "df = pd.read_csv('/content/drive/MyDrive/database/ML Project Database/twitter sentiment.csv', encoding='latin-1', names=column_names)"
      ],
      "metadata": {
        "id": "CeYWJCSdGMLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "biEr6qdKIK3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#counting the missing value\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "IJ0BJBYmIPmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the distribution in the target column\n",
        "df['target'].value_counts()"
      ],
      "metadata": {
        "id": "ToXlSdnSInO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#changing value 4 to 1\n",
        "df['target'] = df['target'].replace(4,1)\n",
        "df[\"target\"].value_counts()"
      ],
      "metadata": {
        "id": "XhdqEOtjJRi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here 0 means Negative twitt and 1 means Positive twitt**"
      ],
      "metadata": {
        "id": "6Ffjp6Y_KENa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steming\n",
        "\n",
        "**Steaming is the process of reducing a word to it's root word. such as: actor, actress, acting = act**"
      ],
      "metadata": {
        "id": "lbmiBYLPKgtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "port_steam = PorterStemmer() #reducing word to root word"
      ],
      "metadata": {
        "id": "FyDcLXmeKCSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#declaring steming function\n",
        "def stemming(content):\n",
        "  stemmed_content = re.sub('[^a-zA-Z]',' ',content) #everything wil be removed except a-z,A-Z\n",
        "  stemmed_content = stemmed_content.lower() #converting everything to lowercase\n",
        "  stemmed_content = stemmed_content.split() #spliting words\n",
        "  stemmed_content = [port_steam.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
        "  stemmed_content = ' '.join(stemmed_content)\n",
        "  return stemmed_content"
      ],
      "metadata": {
        "id": "On4PYh-DKB0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['stem_text'] = df['text'].apply(stemming)"
      ],
      "metadata": {
        "id": "ygGizgd-LXHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "wtjnU3PcLXD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['stem_text'])"
      ],
      "metadata": {
        "id": "SFmbaAMRLW-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"target\"])"
      ],
      "metadata": {
        "id": "HXBZP_YEKBxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Spliting"
      ],
      "metadata": {
        "id": "-D4rFGVan6-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#separating data and label\n",
        "x = df['stem_text'].values\n",
        "y = df['target'].values"
      ],
      "metadata": {
        "id": "rkUuO22Mn2Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data spliting\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=2) #stratify means equal distribution of unique data in test and trainig data , x,y train contains same amount of 0 or 1.\n"
      ],
      "metadata": {
        "id": "xrWlOF5IoStw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape, x_train.shape, x_test.shape)"
      ],
      "metadata": {
        "id": "umPWTjuto391"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting Actual Data to Numeric"
      ],
      "metadata": {
        "id": "dwwicg3lpFpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting actual data to numeric\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "\n",
        "x_train = vectorizer.fit_transform(x_train) #fit transform only for train data\n",
        "x_test = vectorizer.transform(x_test)"
      ],
      "metadata": {
        "id": "PUdmdknMpYgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model\n",
        "\n",
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "RldEK9p0qpV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()"
      ],
      "metadata": {
        "id": "MH81jeNGpYdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "w_OdbZeXpYVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "3qDnXaUyrM2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy score on the training data\n",
        "x_train_prediction = model.predict(x_train)\n",
        "training_data_accuracy = accuracy_score(x_train_prediction, y_train)\n",
        "print(\"Training Data Accuracy: \", training_data_accuracy)"
      ],
      "metadata": {
        "id": "M3Y6m5ykrx2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy score on the test data\n",
        "x_test_prediction = model.predict(x_test)\n",
        "test_data_accuracy = accuracy_score(x_test_prediction, y_test)\n",
        "print(\"Test Data Accuracy: \", test_data_accuracy)"
      ],
      "metadata": {
        "id": "ucvUCkgqsZmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As the training data and test data accuracy is quite close so we can say that, this model is working well.**"
      ],
      "metadata": {
        "id": "sX_dydAmsfuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Saving"
      ],
      "metadata": {
        "id": "-_RnXZX_tIcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "mhm0AkHpsb5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"trained_model.sav\"\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "CucWhPX6tOuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Model for Future Prediction"
      ],
      "metadata": {
        "id": "VusCcCDHttBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the model\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n"
      ],
      "metadata": {
        "id": "eijAUOu4t3Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_name = x_test[200]\n",
        "prediction = loaded_model.predict(X_name)\n",
        "print(prediction)\n",
        "\n",
        "if prediction[0] == 0:\n",
        "  print(\"Negative Tweet\")\n",
        "else:\n",
        "  print(\"Positive Tweet\")"
      ],
      "metadata": {
        "id": "mHYJTihct-Ad"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}